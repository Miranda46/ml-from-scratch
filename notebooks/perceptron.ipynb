{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0402de",
   "metadata": {},
   "source": [
    "# Perceptron en Python\n",
    "Forma más simple:\n",
    "\n",
    "tenemos \n",
    "\n",
    "\n",
    "$output = inputs * weights  + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79d3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1,2,3,4]\n",
    "weights = [-0.5, 2, 1, -1.3]\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca6a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2999999999999998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sum([input * weight for input, weight in zip(inputs, weights)]) + b\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff650c",
   "metadata": {},
   "source": [
    "Haciéndolo de manera más general y convirtiendo $weights$ en un matriz, obtenemos la siguiente función que sirve genéricamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bda35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_calculation(inputs, weights, bias):\n",
    "    # Outputs finales\n",
    "    outputs = []\n",
    "\n",
    "    # Iteramos sobre inputs y bias\n",
    "    for weight_vector, n_bias in zip(weights, bias):\n",
    "        # valor de cada entrada de neurona\n",
    "        output_neuron = 0\n",
    "        for n_input, weight_value in zip(inputs, weight_vector):\n",
    "            # Sumar cada componente\n",
    "            output_neuron += n_input * weight_value\n",
    "        # añadir bias\n",
    "        outputs.append(output_neuron + n_bias)\n",
    "        \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fee479",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "    ]\n",
    "biases = [2, 3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4b2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "print(layer_calculation(inputs, weights, biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b92458",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "Con numpy se puede hacer de manera expedita, dado que tenemos el producto punto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b771c17",
   "metadata": {},
   "source": [
    "Una nuerona sería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b79e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f007ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.2999999999999998)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1,2,3,4]\n",
    "weights = [-0.5, 2, 1, -1.3]\n",
    "b = 0\n",
    "\n",
    "output = np.dot(weights, inputs) + b\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc986fa0",
   "metadata": {},
   "source": [
    "De manera similar podemos ahorrar tiempo a la hora de tener una capa con múltiples perceptrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "340915d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8  , 1.21 , 2.385])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "    ]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = np.dot(weights, inputs) + biases\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a76e91",
   "metadata": {},
   "source": [
    "De manera similar, podemos tomar batches(grupos de inputs), que son útiles en \n",
    "esta situaciones, dado que estabiliza la manera en la que se comporta el cambio\n",
    "de nuestra función a la hora de ser entrenada y aumenta la velocidad en la que\n",
    "es posible entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1480a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([\n",
    "    [1,2,3,2.5],\n",
    "    [2,5,-1,2],\n",
    "    [-1.5,2.7,3.3,-0.8]\n",
    "])\n",
    "\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "])\n",
    "\n",
    "biases = np.array([2,3,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f55c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.dot(inputs, weights.T) + biases\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88f2af",
   "metadata": {},
   "source": [
    "## Capas ocultas\n",
    "Las capas ocultas no son más que agarrar la capa de atrás y usarla para\n",
    "generar una nueva capa, que naturalmente usará estos valores como inputs,\n",
    "y necesitará un nuevo conjunto de pesos y de bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5031 , -1.04185,  2.18525],\n",
       "       [ 0.2434 , -2.7332 ,  2.0687 ],\n",
       "       [-0.99314,  1.41254,  0.88425]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([\n",
    "    [1,2,3,2.5],\n",
    "    [2,5,-1,2],\n",
    "    [-1.5,2.7,3.3,-0.8]\n",
    "])\n",
    "\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "])\n",
    "\n",
    "biases = np.array([2,3,0.5])\n",
    "\n",
    "weights2 = np.array([\n",
    "    [0.1,-0.14,0.5],\n",
    "    [-0.5,0.12,-0.33],\n",
    "    [0.44,0.73,-0.13],\n",
    "])\n",
    "\n",
    "biases2 = np.array([-1,2,-0.5])\n",
    "\n",
    "# calculamos la capa inicial\n",
    "layer1_output = np.dot(inputs, weights.T) + biases\n",
    "# Calculamos la capa oculta usando la salida de la capa anterior\n",
    "layer2_output = np.dot(layer1_output, weights2.T) + biases2\n",
    "layer2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0094e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
